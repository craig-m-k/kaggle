{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a brief analysis of the [Rotten tomatoes dataset](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews) using PySpark.  PySpark's machine learning pipeline is similar to scikit-learn's, and the purpose of this project was to get familiar with Spark and natural language processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PySpark makes use of DataFrames.  DataFrames are similar to those in Pandas, yet with Pandas DataFrames seemingly more feature-rich. Because of this, we'll need Pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting PySpark up and running can be a bit challenging.  On macOS High Sierra, environment variables are a pain, and no amount of `export` in the Terminal let Spark run correctly in Jupyter.  Because of that, I have to set the environment variables manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['JAVA_HOME'] = '/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/'\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--master local[4] pyspark-shell'\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data files are in tab separated values format. Importing them in Pandas then converting to a Spark DataFrame is not efficient but it's simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.tsv', delimiter='\\t')\n",
    "test = pd.read_csv('test.tsv', delimiter='\\t')\n",
    "train_sdf = spark.createDataFrame(train)\n",
    "test_sdf = spark.createDataFrame(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divide the training data into a training set and a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_set, val_set) = train_sdf.randomSplit([0.90, 0.10], seed = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, Tokenizer, IDF, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import IndexToString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a pipeline through which our data passes:\n",
    "\n",
    "phrases -> tokenizer -> countvectorizer -> idf -> stringindexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"Phrase\", outputCol=\"words\")\n",
    "cv = CountVectorizer(vocabSize=2**18, inputCol=\"words\", outputCol='cv',minDF=12)\n",
    "idf = IDF(inputCol='cv', outputCol=\"features\",minDocFreq=12) \n",
    "label_stringIdx = StringIndexer(inputCol = \"Sentiment\", outputCol = \"label\")\n",
    "pipeline = Pipeline(stages=[tokenizer,  cv, idf,  label_stringIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+---------+--------------------+--------------------+--------------------+-----+\n",
      "|PhraseId|SentenceId|              Phrase|Sentiment|               words|                  cv|            features|label|\n",
      "+--------+----------+--------------------+---------+--------------------+--------------------+--------------------+-----+\n",
      "|       1|         1|A series of escap...|        1|[a, series, of, e...|(8796,[0,1,2,3,5,...|(8796,[0,1,2,3,5,...|  2.0|\n",
      "|       2|         1|A series of escap...|        2|[a, series, of, e...|(8796,[0,2,3,9,10...|(8796,[0,2,3,9,10...|  0.0|\n",
      "|       3|         1|            A series|        2|         [a, series]|(8796,[2,325],[1....|(8796,[2,325],[1....|  0.0|\n",
      "|       4|         1|                   A|        2|                 [a]|    (8796,[2],[1.0])|(8796,[2],[1.6136...|  0.0|\n",
      "|       5|         1|              series|        2|            [series]|  (8796,[325],[1.0])|(8796,[325],[6.08...|  0.0|\n",
      "|       6|         1|of escapades demo...|        2|[of, escapades, d...|(8796,[0,3,9,10,1...|(8796,[0,3,9,10,1...|  0.0|\n",
      "|       7|         1|                  of|        2|                [of]|    (8796,[3],[1.0])|(8796,[3],[1.7235...|  0.0|\n",
      "|       8|         1|escapades demonst...|        2|[escapades, demon...|(8796,[0,9,10,14,...|(8796,[0,9,10,14,...|  0.0|\n",
      "|       9|         1|           escapades|        2|         [escapades]|        (8796,[],[])|        (8796,[],[])|  0.0|\n",
      "|      10|         1|demonstrating the...|        2|[demonstrating, t...|(8796,[0,9,10,14,...|(8796,[0,9,10,14,...|  0.0|\n",
      "+--------+----------+--------------------+---------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipelineFit = pipeline.fit(train_set)\n",
    "train_df = pipelineFit.transform(train_set)\n",
    "val_df = pipelineFit.transform(val_set)\n",
    "train_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use logistic regression to perform the classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6440515087449549"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(maxIter=100)\n",
    "lrModel = lr.fit(train_df)\n",
    "predictions = lrModel.transform(val_df)\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Kaggle leaderboard, this score is actually pretty good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to move from the labels created by StringIndexer to the actual Sentiments predicted by the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pipelineFit.transform(test_sdf)\n",
    "test_pred = lrModel.transform(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = IndexToString(inputCol=\"prediction\", outputCol=\"Sentiment\", labels=['2.0', '3.0', '1.0', '4.0', '0.0'])\n",
    "converted = converter.transform(test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I expected that IndexToString would use meta-data to automatically infer the correct Sentiment for each label, but I found that I needed to specify the correct labels myself (in the right order!).  Surely there is a better way to do this.\n",
    "\n",
    "As the final step, I convert the Spark DataFrame to a Pandas DataFrame to make writing the CSV easier. In general, using `toPandas()` for this conversion is pretty slow, so we only convert using the two columns that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pdf = converted[['PhraseId','Sentiment']].toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas complained when I tried to convert `Sentiment` to integer type, so I had to do it in two steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pdf['Sentiment'] = pred_pdf['Sentiment'].astype(float)\n",
    "pred_pdf['Sentiment'] = pred_pdf['Sentiment'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pdf.to_csv('prediction051118-2.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
